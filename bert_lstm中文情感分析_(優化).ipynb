{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0c5c3899",
      "metadata": {
        "id": "0c5c3899",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import jieba\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from transformers import AutoTokenizer, BertModel, BertTokenizer, BertForSequenceClassification, BertConfig, AdamW, get_linear_schedule_with_warmup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ca4ef3c7",
      "metadata": {
        "id": "ca4ef3c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9918956e-0f88-4d76-e359-392b7b11ff55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "MODEL_NAME = 'bert-base-chinese'\n",
        "num_labels = 3\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
        "max_length = 20\n",
        "bs = 32\n",
        "EPOCHS = 2\n",
        "LR = 1e-5\n",
        "WARMUP_STEPS = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 初始化BERT的分词器\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "\n",
        "def load_dataset(filepath, max_len):\n",
        "    labels = []\n",
        "    sentences = []\n",
        "\n",
        "    # 读取txt文件\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            # 去掉行末尾的换行符并用逗号分割\n",
        "            line = line.strip()\n",
        "            if ',' not in line:\n",
        "                continue  # 如果没有逗号，跳过\n",
        "            label, sentence = line.split(',', 1)\n",
        "\n",
        "            # 将标签和句子添加到相应的列表\n",
        "            labels.append(int(label))\n",
        "            sentences.append(sentence)\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # 对每个句子进行编码\n",
        "    for data in sentences:\n",
        "        encoded_data = tokenizer.encode_plus(\n",
        "            text=data,                      # 句子\n",
        "            add_special_tokens=True,        # 添加特殊标记，如[CLS]和[SEP]\n",
        "            max_length=max_len,             # 截断或填充到最大长度\n",
        "            padding='max_length',           # 填充到max_length\n",
        "            return_attention_mask=True,     # 返回attention mask\n",
        "            truncation=True                 # 截断长句子\n",
        "        )\n",
        "\n",
        "        # 将编码后的数据添加到列表中\n",
        "        input_ids.append(encoded_data.get('input_ids'))\n",
        "        attention_masks.append(encoded_data.get('attention_mask'))\n",
        "\n",
        "    # 将列表转换为tensor\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return input_ids, attention_masks, labels\n"
      ],
      "metadata": {
        "id": "E5c2RAD3keB5"
      },
      "id": "E5c2RAD3keB5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a0adb27b",
      "metadata": {
        "id": "a0adb27b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train_dataset = load_dataset('dataset_new.txt', max_len = max_length)\n",
        "valid_dataset = load_dataset('dataset_test.txt', max_len = max_length)\n",
        "\n",
        "train_data = TensorDataset(train_dataset[0], train_dataset[1],train_dataset[2])\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size = bs)\n",
        "\n",
        "val_data = TensorDataset(valid_dataset[0],valid_dataset[1],valid_dataset[2])\n",
        "val_loader = DataLoader(val_data,shuffle=True, batch_size = bs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義自己的bert模型\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dimension):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        embedding_dim = self.bert.config.to_dict()['hidden_size']\n",
        "\n",
        "        self.LSTM = nn.LSTM(embedding_dim,hidden_dimension,bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.out = nn.Linear(hidden_dimension * 2, 3)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "\n",
        "\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        encoded_layers = outputs[0]\n",
        "\n",
        "        #encoded_layers = encoded_layers.permute(1, 0, 2)\n",
        "\n",
        "        enc_hiddens, (last_hidden, last_cell) = self.LSTM(encoded_layers)\n",
        "        output_hidden = torch.cat((enc_hiddens[:,-1, :256],enc_hiddens[:,0, 256:]),dim=-1)\n",
        "        output_hidden = F.dropout(output_hidden,0.2)\n",
        "\n",
        "        logits = self.out(output_hidden)\n",
        "\n",
        "        return logits\n",
        "def initialize_model(epochs=EPOCHS):\n",
        "    bert_classifier = BertClassifier(hidden_dimension=256)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),lr=LR)\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=WARMUP_STEPS,num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "metadata": {
        "id": "AJt8EcNFvChz"
      },
      "id": "AJt8EcNFvChz",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#定義訓練跟評估\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=EPOCHS , evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for s,batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits.view(-1, 3), b_labels.view(-1))\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # return loss, logits\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (s % 20 == 0 and s != 0) or (s == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {s:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        if evaluation == True:\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n"
      ],
      "metadata": {
        "id": "EgXxBpXzvWgt"
      },
      "id": "EgXxBpXzvWgt",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=EPOCHS)\n",
        "train(bert_classifier, train_loader, val_loader, epochs=EPOCHS, evaluation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e06c2101bb824e9aab84bda841c8dc79",
            "3545687081b8414097f901c1cffd3035",
            "978e1d5fef984db0b82df0a09aedf0b2",
            "e334c45fbae945f9aefd4b0d565d047d",
            "b5735ac6a552489ca336540c7b4e504b",
            "4a3c673dfc81438081e67853f98d28b2",
            "97145c28e46745268ea43983e06a0ab3",
            "32655926d48e4ed5a8859f0b63ddad5c",
            "d0076eab381649e2ac1d6106d851d302",
            "5f6238ee31684169a53da1e4c287f146",
            "0e08bb8a67084617818f3590a619e038"
          ]
        },
        "id": "CWjieekrvgp0",
        "outputId": "aa51bfd8-6fb8-488f-9c72-06740d709af0"
      },
      "id": "CWjieekrvgp0",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e06c2101bb824e9aab84bda841c8dc79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.067690   |     -      |     -     |   4.35   \n",
            "   1    |   40    |   0.949167   |     -      |     -     |   2.49   \n",
            "   1    |   60    |   0.802394   |     -      |     -     |   2.51   \n",
            "   1    |   80    |   0.667499   |     -      |     -     |   2.53   \n",
            "   1    |   100   |   0.469111   |     -      |     -     |   2.53   \n",
            "   1    |   120   |   0.308112   |     -      |     -     |   2.53   \n",
            "   1    |   140   |   0.282987   |     -      |     -     |   2.48   \n",
            "   1    |   160   |   0.234066   |     -      |     -     |   2.51   \n",
            "   1    |   180   |   0.181462   |     -      |     -     |   2.53   \n",
            "   1    |   200   |   0.215741   |     -      |     -     |   2.52   \n",
            "   1    |   220   |   0.198554   |     -      |     -     |   2.58   \n",
            "   1    |   240   |   0.189979   |     -      |     -     |   2.59   \n",
            "   1    |   260   |   0.231892   |     -      |     -     |   2.67   \n",
            "   1    |   280   |   0.176012   |     -      |     -     |   2.74   \n",
            "   1    |   300   |   0.235234   |     -      |     -     |   2.68   \n",
            "   1    |   320   |   0.214297   |     -      |     -     |   2.72   \n",
            "   1    |   340   |   0.181286   |     -      |     -     |   2.54   \n",
            "   1    |   360   |   0.167129   |     -      |     -     |   2.56   \n",
            "   1    |   380   |   0.185510   |     -      |     -     |   2.56   \n",
            "   1    |   400   |   0.152270   |     -      |     -     |   2.56   \n",
            "   1    |   420   |   0.128690   |     -      |     -     |   2.56   \n",
            "   1    |   440   |   0.144240   |     -      |     -     |   2.56   \n",
            "   1    |   460   |   0.153312   |     -      |     -     |   2.60   \n",
            "   1    |   480   |   0.159035   |     -      |     -     |   2.60   \n",
            "   1    |   500   |   0.144379   |     -      |     -     |   2.58   \n",
            "   1    |   520   |   0.153196   |     -      |     -     |   2.90   \n",
            "   1    |   540   |   0.133413   |     -      |     -     |   2.59   \n",
            "   1    |   560   |   0.134197   |     -      |     -     |   2.61   \n",
            "   1    |   580   |   0.126594   |     -      |     -     |   2.60   \n",
            "   1    |   600   |   0.111778   |     -      |     -     |   2.59   \n",
            "   1    |   620   |   0.132409   |     -      |     -     |   2.60   \n",
            "   1    |   640   |   0.130007   |     -      |     -     |   2.60   \n",
            "   1    |   660   |   0.147833   |     -      |     -     |   2.63   \n",
            "   1    |   680   |   0.128839   |     -      |     -     |   2.79   \n",
            "   1    |   700   |   0.108511   |     -      |     -     |   2.70   \n",
            "   1    |   720   |   0.151028   |     -      |     -     |   2.74   \n",
            "   1    |   740   |   0.121799   |     -      |     -     |   2.63   \n",
            "   1    |   760   |   0.116519   |     -      |     -     |   2.65   \n",
            "   1    |   780   |   0.084316   |     -      |     -     |   2.63   \n",
            "   1    |   800   |   0.148466   |     -      |     -     |   2.63   \n",
            "   1    |   820   |   0.105796   |     -      |     -     |   2.63   \n",
            "   1    |   840   |   0.105605   |     -      |     -     |   2.64   \n",
            "   1    |   860   |   0.112730   |     -      |     -     |   2.67   \n",
            "   1    |   880   |   0.116950   |     -      |     -     |   2.64   \n",
            "   1    |   900   |   0.117524   |     -      |     -     |   2.65   \n",
            "   1    |   920   |   0.071716   |     -      |     -     |   2.63   \n",
            "   1    |   925   |   0.165823   |     -      |     -     |   0.67   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.226655   |  0.055309  |   99.22   |  122.71  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.095408   |     -      |     -     |   2.80   \n",
            "   2    |   40    |   0.047538   |     -      |     -     |   2.66   \n",
            "   2    |   60    |   0.097126   |     -      |     -     |   2.65   \n",
            "   2    |   80    |   0.088687   |     -      |     -     |   2.66   \n",
            "   2    |   100   |   0.073652   |     -      |     -     |   2.96   \n",
            "   2    |   120   |   0.093370   |     -      |     -     |   3.25   \n",
            "   2    |   140   |   0.084248   |     -      |     -     |   2.66   \n",
            "   2    |   160   |   0.102432   |     -      |     -     |   2.67   \n",
            "   2    |   180   |   0.082745   |     -      |     -     |   2.69   \n",
            "   2    |   200   |   0.069726   |     -      |     -     |   2.72   \n",
            "   2    |   220   |   0.064347   |     -      |     -     |   2.70   \n",
            "   2    |   240   |   0.059229   |     -      |     -     |   2.68   \n",
            "   2    |   260   |   0.073701   |     -      |     -     |   2.68   \n",
            "   2    |   280   |   0.064462   |     -      |     -     |   2.68   \n",
            "   2    |   300   |   0.086845   |     -      |     -     |   2.71   \n",
            "   2    |   320   |   0.048303   |     -      |     -     |   2.71   \n",
            "   2    |   340   |   0.065377   |     -      |     -     |   2.70   \n",
            "   2    |   360   |   0.056668   |     -      |     -     |   2.70   \n",
            "   2    |   380   |   0.093648   |     -      |     -     |   2.70   \n",
            "   2    |   400   |   0.075273   |     -      |     -     |   2.74   \n",
            "   2    |   420   |   0.039130   |     -      |     -     |   2.72   \n",
            "   2    |   440   |   0.095364   |     -      |     -     |   2.72   \n",
            "   2    |   460   |   0.059383   |     -      |     -     |   2.71   \n",
            "   2    |   480   |   0.075251   |     -      |     -     |   2.73   \n",
            "   2    |   500   |   0.073166   |     -      |     -     |   2.74   \n",
            "   2    |   520   |   0.080559   |     -      |     -     |   2.74   \n",
            "   2    |   540   |   0.050684   |     -      |     -     |   2.72   \n",
            "   2    |   560   |   0.072547   |     -      |     -     |   2.73   \n",
            "   2    |   580   |   0.108166   |     -      |     -     |   2.74   \n",
            "   2    |   600   |   0.073691   |     -      |     -     |   2.73   \n",
            "   2    |   620   |   0.064994   |     -      |     -     |   2.73   \n",
            "   2    |   640   |   0.084864   |     -      |     -     |   2.74   \n",
            "   2    |   660   |   0.089700   |     -      |     -     |   2.73   \n",
            "   2    |   680   |   0.056805   |     -      |     -     |   2.77   \n",
            "   2    |   700   |   0.095899   |     -      |     -     |   2.75   \n",
            "   2    |   720   |   0.071232   |     -      |     -     |   2.74   \n",
            "   2    |   740   |   0.087030   |     -      |     -     |   2.75   \n",
            "   2    |   760   |   0.046560   |     -      |     -     |   2.74   \n",
            "   2    |   780   |   0.083104   |     -      |     -     |   2.78   \n",
            "   2    |   800   |   0.076268   |     -      |     -     |   2.77   \n",
            "   2    |   820   |   0.050433   |     -      |     -     |   2.74   \n",
            "   2    |   840   |   0.076259   |     -      |     -     |   2.74   \n",
            "   2    |   860   |   0.043756   |     -      |     -     |   2.77   \n",
            "   2    |   880   |   0.084238   |     -      |     -     |   2.76   \n",
            "   2    |   900   |   0.046625   |     -      |     -     |   2.75   \n",
            "   2    |   920   |   0.067680   |     -      |     -     |   2.77   \n",
            "   2    |   925   |   0.079820   |     -      |     -     |   0.63   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.073454   |  0.038834  |   99.11   |  126.88  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "37e2c042",
      "metadata": {
        "id": "37e2c042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80183c59-c4de-4a35-e113-584f33c49254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "开始测试...\n"
          ]
        }
      ],
      "source": [
        "torch.save(bert_classifier.state_dict(), 'bert_lstm.ckpt')\n",
        "\n",
        "print('开始测试...')\n",
        "bert_classifier.eval()\n",
        "test_result = []\n",
        "for input_ids, attention_mask, labels in zip(valid_dataset[0], valid_dataset[1], valid_dataset[2]):\n",
        "    b_input_ids = input_ids.unsqueeze(0).to(device)\n",
        "    b_attn_mask = attention_mask.unsqueeze(0).to(device)\n",
        "    b_labels = labels.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_classifier(b_input_ids, attention_mask=b_attn_mask)\n",
        "        pre = outputs.argmax(dim=1)\n",
        "        tokens = [tokenizer.convert_ids_to_tokens(id.item()) for id in b_input_ids[0]]\n",
        "        test_result.append([b_labels.item(), pre.item(), tokens])\n",
        "       #b_labels.item()：获取真实标签的值。pre.item()：获取模型预测的值。tokenizer.convert_ids_to_tokens(b_input_ids)：将输入的 token IDs 转换回原始文本形\n",
        "# 写入csv文件\n",
        "df = pd.DataFrame(test_result)\n",
        "df.to_csv('test_result.csv',index=False, header=['real', 'predict','text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test_result.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rPAX5ob6Dz-",
        "outputId": "1301736a-6e3a-4850-cbbf-9937c5a6b184"
      },
      "id": "1rPAX5ob6Dz-",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     real  predict                                               text\n",
            "0       1        1  ['[CLS]', '好', '吧', '移', '动', '年', '优', '惠', '...\n",
            "1       1        1  ['[CLS]', '好', '听', '歌', '曲', '名', '单', '[SEP]...\n",
            "2       1        1  ['[CLS]', '常', '州', '市', '贸', '中', '心', '干', '...\n",
            "3       0        0  ['[CLS]', '无', '聊', '时', '候', '还', '可', '以', '...\n",
            "4       0        0  ['[CLS]', '就', '想', '知', '道', '怎', '么', '那', '...\n",
            "..    ...      ...                                                ...\n",
            "119     1        1  ['[CLS]', '里', '面', '阿', '狸', '可', '爱', '[SEP]...\n",
            "120     0        0  ['[CLS]', '没', '用', '系', '统', '设', '置', '[SEP]...\n",
            "121     1        1  ['[CLS]', '可', '爱', '自', '恋', '吧', '好', '困', '...\n",
            "122     1        1  ['[CLS]', '通', '知', '求', '主', '动', '活', '跃', '...\n",
            "123     0        0  ['[CLS]', '我', '试', '着', '那', '样', '做', '可', '...\n",
            "\n",
            "[124 rows x 3 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e06c2101bb824e9aab84bda841c8dc79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3545687081b8414097f901c1cffd3035",
              "IPY_MODEL_978e1d5fef984db0b82df0a09aedf0b2",
              "IPY_MODEL_e334c45fbae945f9aefd4b0d565d047d"
            ],
            "layout": "IPY_MODEL_b5735ac6a552489ca336540c7b4e504b"
          }
        },
        "3545687081b8414097f901c1cffd3035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3c673dfc81438081e67853f98d28b2",
            "placeholder": "​",
            "style": "IPY_MODEL_97145c28e46745268ea43983e06a0ab3",
            "value": "model.safetensors: 100%"
          }
        },
        "978e1d5fef984db0b82df0a09aedf0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32655926d48e4ed5a8859f0b63ddad5c",
            "max": 411553788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0076eab381649e2ac1d6106d851d302",
            "value": 411553788
          }
        },
        "e334c45fbae945f9aefd4b0d565d047d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6238ee31684169a53da1e4c287f146",
            "placeholder": "​",
            "style": "IPY_MODEL_0e08bb8a67084617818f3590a619e038",
            "value": " 412M/412M [00:05&lt;00:00, 26.0MB/s]"
          }
        },
        "b5735ac6a552489ca336540c7b4e504b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a3c673dfc81438081e67853f98d28b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97145c28e46745268ea43983e06a0ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32655926d48e4ed5a8859f0b63ddad5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0076eab381649e2ac1d6106d851d302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f6238ee31684169a53da1e4c287f146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e08bb8a67084617818f3590a619e038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}